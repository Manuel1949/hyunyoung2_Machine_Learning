{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorlfow's Neural Network Convolution\n",
    "\n",
    "The convolution ops convolves a 2-D filter over a batch of images, applying the filter to each window of each image of the appropriate size. There are different verions of filter between generic vs. specific filters.\n",
    "\n",
    "  - **conv2d:** Arbirtrary filters that can mix channels(R, G, B) together.\n",
    "  \n",
    "  - **depthwise_conv2d:** Filters that operate on each channel independently.\n",
    "  \n",
    "  - **separable_conv2d:** A depthwise spatial filter followed by a pointwise filter.\n",
    "  \n",
    "except for thigs above, Tensorflow is providing several version of convolution filter, BUT, in here, I would explain padding scheme with conv2d like this:\n",
    "\n",
    "\n",
    "![Kim, Y. (2014). Convolutional Neural Networks for Sentence Classification](https://raw.githubusercontent.com/hyunyoung2/hyunyoung2_Machine_Learning/master/Tutorial/Tensorflow/05.Convolution/Images/01-Tensorflow-s_Neural_Network_Convolution/Convolutional_Neural_Networks_for_Sentence_Classification.png)\n",
    "\n",
    "i.e. As you can see above, I am going to convolve a window of a sentence with conv2d filter. \n",
    "\n",
    "\n",
    "The filter is applied to image patches of the same size as the filter and strided acoording to strides argument. \n",
    "\n",
    "the argument is strides=[1, 1, 1, 1], it means every offset to move the filter, each postion of strides argument from left means batch, height, width, channel(e.g. NHWC format).\n",
    "\n",
    "Ignoring channels for the moments, assume that the 4-D input has shape of [batch, input_height, input_width, input_channels] and the 4-D filter has shape [filter_height, filter_width, input_channel, output_channel]. The spatial of the convolution ops depend on the padding scheme chosen: \"SAME\" or \"VALID\".\n",
    "\n",
    "From now on, if I say padding, it means zero padding. i.e. I am always padding zero value like this.\n",
    "\n",
    "![http://cs231n.github.io/convolutional-networks/](https://raw.githubusercontent.com/hyunyoung2/hyunyoung2_Machine_Learning/master/Tutorial/Tensorflow/05.Convolution/Images/01-Tensorflow-s_Neural_Network_Convolution/cs231_conv.png)\n",
    "\n",
    "\n",
    "\n",
    "## SAME Scheme \n",
    "\n",
    "\"SAME\" Scheme mean height and width size is the same between input and output. i.e. \"SAME\" scheme always pad zero value to evaluate edge part of image. \n",
    "\n",
    "Tensorflow's \"SAME\" padding scheme use the smallest possible padding to achive the desired output size.\n",
    "\n",
    "If you want to know about SAME scheme more, visit [Notes on SAME Convolution padding](https://www.tensorflow.org/versions/r1.8/api_guides/python/nn#Notes_on_SAME_Convolution_Padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Under SAME Scheme ======\n",
      "output_height: 4.0\n",
      "output_width: 300.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_height = 4 # Image Height\n",
    "input_width = 300 # Image Width\n",
    "\n",
    "filter_height = 2 # filter Height\n",
    "filter_width = 300 # filter Width\n",
    "\n",
    "\n",
    "# batch, height, width, channel\n",
    "strides = [1, 1, 1, 1]\n",
    "\n",
    "# Same Scheme : padding like things below\n",
    "\n",
    "float_height = float(input_height) / float(strides[1])\n",
    "float_width = float(input_width) / float(strides[2])\n",
    "output_height = np.ceil(float_height)\n",
    "output_width = np.ceil(float_width)\n",
    "\n",
    "print(\"====== Under SAME Scheme ======\")\n",
    "print(\"output_height: {}\".format(output_height))\n",
    "print(\"output_width: {}\".format(output_width))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, input height and input width is the same from output height and output width.\n",
    "finally, the padding on top, bottom, left and right are :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad along height and width...\n",
      "pad along height: 1\n",
      "pad along width: 299\n",
      "Padding size on top, bottom, left and right\n",
      "top: 0\n",
      "bottom: 1\n",
      "left: 149\n",
      "right: 150\n"
     ]
    }
   ],
   "source": [
    "# SAME Scheme\n",
    "if (input_height % strides[1] == 0):\n",
    "    pad_along_height = max(filter_height - strides[1], 0)\n",
    "else:\n",
    "    pad_along_height = max(filter_height - (input_height % strides[1]), 0)\n",
    "if (input_width % strides[2] == 0):\n",
    "    pad_along_width = max(filter_width - strides[2], 0)\n",
    "else:\n",
    "    pad_along_width = max(filter_width - (input_width % strides[2]), 0)\n",
    "\n",
    "    \n",
    "print(\"pad along height and width...\")\n",
    "print(\"pad along height: {}\".format(pad_along_height))\n",
    "print(\"pad along width: {}\".format(pad_along_width))\n",
    "pad_top = pad_along_height // 2 # divied by 2\n",
    "pad_bottom = pad_along_height - pad_top\n",
    "pad_left = pad_along_width // 2\n",
    "pad_right = pad_along_width - pad_left    \n",
    "\n",
    "print(\"Padding size on top, bottom, left and right\")\n",
    "print(\"top: {}\".format(pad_top))\n",
    "print(\"bottom: {}\".format(pad_bottom))\n",
    "print(\"left: {}\".format(pad_left))\n",
    "print(\"right: {}\".format(pad_right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the above case, there are the division by 2 to separate padding in height to top and bottom, also padding in weight to left and right. in this case, the bottom and right sides always get the one additional padded pixel.\n",
    "\n",
    "This method is different from the others libraries such as cuDNN and Caffe, which explicitly specify the number of padded pixels and always pad the same number of pixels on both sides. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VALID Scheme on padding \n",
    "\n",
    "\"VALID\" scheme don't use padding. \n",
    "\n",
    "So if you use \"VALID\" scheme, output size shrinks.\n",
    "\n",
    "The following is a example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Under VALID Scheme ======\n",
      "output_height: 3.0\n",
      "output_width: 3.0\n",
      "VALID Schem is no padding\n"
     ]
    }
   ],
   "source": [
    "input_height = 5 # Image Height\n",
    "input_width = 5 # Image Width\n",
    "\n",
    "filter_height = 3 # filter Height\n",
    "filter_width = 3 # filter Width\n",
    "\n",
    "# Valid Scheme : no padding is used.\n",
    "\n",
    "float_height = float(input_height - filter_height + 1) / float(strides[1])\n",
    "float_width = float(input_width - filter_width + 1) / float(strides[2])\n",
    "output_height = np.ceil(float_height)\n",
    "output_width = np.ceil(float_width)\n",
    "\n",
    "print(\"====== Under VALID Scheme ======\")\n",
    "print(\"output_height: {}\".format(output_height))\n",
    "print(\"output_width: {}\".format(output_width))\n",
    "print(\"VALID Schem is no padding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of convolution can be computed as follows. i.e. conv computation is linear function like : F(x)=xW+b\n",
    "\n",
    "If the following is using \"VALID\" Scheme, as you could see, its output height size and width size is the same from the evaluation of code above.\n",
    "\n",
    "![http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif](https://raw.githubusercontent.com/hyunyoung2/hyunyoung2_Machine_Learning/master/Tutorial/Tensorflow/05.Convolution/Images/01-Tensorflow-s_Neural_Network_Convolution/Convolution_schematic.gif)\n",
    "\n",
    "Given the output size and the padding, the output can be computed as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$output[b, i, j, :] = sum_{d_i, d_j} input[b, strides[1] * i + d_i - pad_{top},                           strides[2] * j + d_j - pad_{left}, ...] *filter[d_i, d_j,\\ ...]$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Math\n",
    "Math(r\"output[b, i, j, :] = sum_{d_i, d_j} input[b, strides[1] * i + d_i - pad_{top},\\\n",
    "                           strides[2] * j + d_j - pad_{left}, ...] *filter[d_i, d_j,\\ ...]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where any value outside the orginal input image resion are considered zero (i.e. padding value around the border of the image is always zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference \n",
    "\n",
    " - [Tensorlfow's Neural Network Convolution ver 1.8](https://www.tensorflow.org/versions/r1.8/api_guides/python/nn#Convolution)\n",
    " \n",
    " - [Tensorflow's the smallest padding on SAME Scheme](https://www.tensorflow.org/versions/r1.8/api_guides/python/nn#Notes_on_SAME_Convolution_Padding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
